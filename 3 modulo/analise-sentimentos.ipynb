{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.datasets import imdb\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers import Flatten\nimport copy\n\npalavras_mais_usadas = 10000\ntamanho_maximo = 500\ntamanho_da_camada_de_incorporacao = 32\n\n(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=palavras_mais_usadas)\n\nx_train = sequence.pad_sequences(x_train,tamanho_maximo)\nx_test = sequence.pad_sequences(x_test,tamanho_maximo)",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "json_dicionario = imdb.get_word_index()\ndicionarioPalavras = list(json_dicionario.keys())\ndicionarioNumeros = list(json_dicionario.values())\ndef traduzir(revisao):\n    retorno = []\n    for palavra in revisao:\n        if(palavra == 0):\n            retorno.append('')\n        elif(palavra == 1):\n            retorno.append('>')\n        elif(palavra == 2):\n            retorno.append('?')\n        else:\n            index = dicionarioNumeros.index(palavra - 3)\n            retorno.append(dicionarioPalavras[index])\n    return ' '.join(retorno)  ",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model = Sequential()\nmodel.add(Embedding(palavras_mais_usadas, tamanho_da_camada_de_incorporacao, input_length = tamanho_maximo))\nmodel.add(Flatten())\nmodel.add(Dense(16,activation='relu'))\nmodel.add(Dense(16,activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\nprint(model.summary())",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "WARNING:tensorflow:From /home/nbuser/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:182: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\nModel: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 500, 32)           320000    \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 16000)             0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 16)                256016    \n_________________________________________________________________\ndense_2 (Dense)              (None, 16)                272       \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 17        \n=================================================================\nTotal params: 576,305\nTrainable params: 576,305\nNon-trainable params: 0\n_________________________________________________________________\nNone\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "treino = model.fit(x_train,y_train,validation_data = (x_test,y_test), epochs=3, batch_size=128 )",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:414: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Train on 25000 samples, validate on 25000 samples\nEpoch 1/3\n25000/25000 [==============================] - 13s 537us/step - loss: 0.5974 - accuracy: 0.6208 - val_loss: 0.3250 - val_accuracy: 0.8617\nEpoch 2/3\n19200/25000 [======================>.......] - ETA: 2s - loss: 0.2271 - accuracy: 0.9118",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set()\n%matplotlib inline\nprecisao = treino.history['accuracy']\nvalidacao = treino.history['val_accuracy']\nepochs = range(1, len(precisao) + 1)\nplt.plot(epochs, precisao, '-', label='Precisão do treinamento')\nplt.plot(epochs, validacao, ':', label='Precisão da validação')\nplt.title('Precisão do treinamento e da validação')\nplt.xlabel('Época')\nplt.ylabel('Precisão')\nplt.legend(loc='upper left')\nplt.plot()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "scores = model.evaluate(x_test,y_test,verbose=0)\nprint(\"Accuracy: %.2f%%\" % (scores[1] * 100))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import string\nimport numpy as np\ndef analise(texto):\n    tabela = str.maketrans(\"\",\"\", string.punctuation)\n    traducao = texto.translate(tabela)\n    traducao = traducao.lower().split(\" \")\n    traducao = [palavra for palavra in traducao if palavra.isalpha()]\n\n    \n    critica = []\n    critica.append(1)\n    for palavra in traducao:\n        if palavra in json_dicionario and json_dicionario[palavra] <= palavras_mais_usadas:\n            critica.append(json_dicionario[palavra])\n        else:\n            critica.append(2)\n    padded_input = sequence.pad_sequences([critica], maxlen=tamanho_maximo)\n    result = model.predict(np.array([padded_input][0]))[0][0]\n    return result\nprint(analise(\"this movie was wonderful.\"))\nprint(analise('Easily the most stellar experience I have ever had.'))\nprint(analise('The long lines and poor customer service really turned me off.'))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}